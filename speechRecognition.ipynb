{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Simple speech recognition utilizing MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessities\n",
    "First, we import aux functions from $\\texttt{preprocess.py}$ as well as Keras and Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *  # Import all the preprocessing functions\n",
    "import keras  # Keras as frontend\n",
    "from keras.models import Sequential  # Sequential NN model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D  # Useful layers to be used\n",
    "from keras.utils import to_categorical  # One-hot encoding\n",
    "import matplotlib.pyplot as plt  # Graphical representations and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We want matrices of dimensions $20\\times20$. This is arbitrary, but less MFCCs contain less info, so $20\\times20$ is a good way to go.\n",
    "We call `transformData` function which does the MFC transformation on each of the $\\textit{.wav}$ files contained inside the folders within the $\\texttt{./data/}$ folder, and packs them in tensors and saves as $\\textit{.npy}$ files. \n",
    "`getTrainTest` unpacks these files, concatenates all of the matrices in one tensor, as well as their labels in one array, then calls `train_test_split` from $\\textit{scikitlearn}$ to obtain training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dimensions of matrices MFC transform\n",
    "# produces from .wav files\n",
    "M = 20\n",
    "N = 20\n",
    "\n",
    "# Save data to array file first\n",
    "transformData(dim=[M,N])\n",
    "\n",
    "# Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = getTrainTestData(splitRatio=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare everything for the network\n",
    "\n",
    "We define various aux variables in order to construct the network and define its behaviour, such as number of epochs network will be trained for, batch size of data provied to the network, number of output classes/nodes of the network... Then we reshape the datasets into 4D tensors, first dimension being the number of matrices in the dataset, M and N dimensions of those matrices, and 4th argument being the number of channels per matrix (channels in terms of RGB channels in color images, which here is simply 1), in order for Keras to accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training features\n",
    "channels = 1 # Fourth dimension of the data\n",
    "             # network is receiving\n",
    "epochs = 100 # Iterate epochs times over\n",
    "             # training dataset\n",
    "batchSize = 100   # Train network in batches\n",
    "numOfClasses = 5  # This is the number of output\n",
    "                  # neurons and depends on classes\n",
    "                  # of .wav files which were provided\n",
    "                  # from Kaggle dataset\n",
    "\n",
    "# CNN expects tensor as input, aka a MxN \"picture\"\n",
    "# with channel channels \n",
    "X_train = X_train.reshape(X_train.shape[0], M, N, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], M, N, channels)\n",
    "\n",
    "# One-hot encoding of outputs \n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network architecture\n",
    "\n",
    "Next we define a function which returns `Sequenital` NN model with architecture defined by the layers we stack, which are mostly convolutional ones, dropouts which downsize the intermediate features to alleviate the burden of large computational costs, and a fully connected layer at output with $\\texttt{numOfClases}$ nodes. We shall train the network using standardized `keras.losses.categorical_crossentropy` loss function while trying to obtain the best accuracy possible.\n",
    "\n",
    "We define one more function which is passed a path to the $\\textit{.wav}$ file and a NN model, and returns the prediction of the network regarding the classification of the word spoken in that audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CONSTRUCT_NETWORK\n",
    "    Function which forms a sequential CNN network with\n",
    "    provided layers\n",
    "    \n",
    "    input:  none\n",
    "    output: model - constructed NN\n",
    "\"\"\"\n",
    "def constructNetwork():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(M, N, channels)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(numOfClasses, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\"\"\" PREDICT\n",
    "    For passed .wav file as input argument, function calculates its\n",
    "    MFCC, passes them to CNN and provides estimation of class the spoken\n",
    "    word belongs to\n",
    "    \n",
    "    input:  filePath - path to .wav file\n",
    "            model - NN model to pass the MFCCs\n",
    "    output: \n",
    "\"\"\"\n",
    "def predict(filePath, model):\n",
    "    # Process the .wav file\n",
    "    sample = audio2mfcc(filePath)\n",
    "    # reshape it so it matches CNNs input dimensions\n",
    "    sampleReshaped = sample.reshape(1, M, N, channels)\n",
    "    # return the label of the output neuron which produces\n",
    "    # largest output\n",
    "    return getLabels()[0][np.argmax(model.predict(sampleReshaped))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "\n",
    "We construct and train the network on prepared training dataset while using test set as validation. This will stop network from overfitting the training set while at the same time gaining accuracy on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the CNN\n",
    "model = constructNetwork()\n",
    "# Train it and validate\n",
    "history = model.fit(X_train, y_train_hot, batch_size=batchSize, epochs=epochs, verbose=1, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies and losses\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy on training set')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy on test set')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss on training set')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss on test set')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate network\n",
    "\n",
    "Now we can se the accuracy of our network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(X_test, y_test_hot)\n",
    "print(eval_loss)\n",
    "print(eval_acc*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Test network prediction on random audio file from each of the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words,_,_ = getLabels('./data/')\n",
    "\n",
    "for word in words:\n",
    "    files = getLabels('./data/'+ word)\n",
    "    random_file = './data/'+word + '/'+ files[0][np.random.randint(1,max(files[1]))]\n",
    "    print(random_file)\n",
    "    print(predict(random_file, model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
